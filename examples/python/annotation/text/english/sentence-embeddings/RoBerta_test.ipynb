{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4WQLLrIUA9cg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9922ba64-4447-4fbf-b4c3-d9bfc4a1f795"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing PySpark 3.4.4 and Spark NLP 6.0.4\n",
            "setup Colab for PySpark 3.4.4 and Spark NLP 6.0.4\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.4/311.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.8/718.8 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dataproc-spark-connect 0.7.5 requires pyspark[connect]~=3.5.1, but you have pyspark 3.4.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! wget -q http://setup.johnsnowlabs.com/colab.sh -O - | bash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KzMHa0HdA9ch",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30993f33-f0bc-4e1d-ed47-f253cf862a48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version 6.0.4\n",
            "Apache Spark version: 3.4.4\n"
          ]
        }
      ],
      "source": [
        "import sparknlp\n",
        "\n",
        "spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version\", sparknlp.version())\n",
        "print(\"Apache Spark version:\", spark.version)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sparknlp.base import DocumentAssembler, EmbeddingsFinisher, MultiDocumentAssembler\n",
        "from sparknlp.annotator import Tokenizer\n",
        "from pyspark.ml import Pipeline"
      ],
      "metadata": {
        "id": "ctfmpiPq2IFm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sparknlp.annotator import RoBertaEmbeddings"
      ],
      "metadata": {
        "id": "Hqx3QlRWzT7R"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "should use `roberta_base` by deafult, is using `roberta_base` ✅"
      ],
      "metadata": {
        "id": "gsZ5chFQ3Gmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = DocumentAssembler() \\\n",
        "     .setInputCol(\"text\") \\\n",
        "     .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "     .setInputCols([\"document\"]) \\\n",
        "     .setOutputCol(\"token\")\n",
        "\n",
        "embeddings = RoBertaEmbeddings.pretrained() \\\n",
        "     .setInputCols([\"document\", \"token\"]) \\\n",
        "     .setOutputCol(\"embeddings\") \\\n",
        "     .setCaseSensitive(True)\n",
        "\n",
        "embeddingsFinisher = EmbeddingsFinisher() \\\n",
        "     .setInputCols([\"embeddings\"]) \\\n",
        "     .setOutputCols(\"finished_embeddings\") \\\n",
        "     .setOutputAsVector(True) \\\n",
        "     .setCleanAnnotations(False)\n",
        "\n",
        "pipeline = Pipeline() \\\n",
        "     .setStages([\n",
        "       documentAssembler,\n",
        "       tokenizer,\n",
        "       embeddings,\n",
        "       embeddingsFinisher\n",
        "     ])\n",
        "\n",
        "data = spark.createDataFrame([\n",
        "    [\"This is a sentence.\"]\n",
        "]).toDF(\"text\")\n",
        "\n",
        "model = pipeline.fit(data)\n",
        "result = model.transform(data)\n",
        "\n",
        "result.selectExpr(\"explode(finished_embeddings) as result\").show(5, 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVHludGFMSCk",
        "outputId": "1fa772ae-1b54-4a13-8ed3-fe7f134def34"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "roberta_base download started this may take some time.\n",
            "Approximate size to download 284.2 MB\n",
            "[OK!]\n",
            "+--------------------------------------------------------------------------------+\n",
            "|                                                                          result|\n",
            "+--------------------------------------------------------------------------------+\n",
            "|[0.09378593415021896,0.13879825174808502,0.05456104129552841,-0.0982267111539...|\n",
            "|[0.3181464672088623,0.19426730275154114,0.1143038421869278,-0.056538678705692...|\n",
            "|[0.10648765414953232,-0.0962962955236435,-0.0707668587565422,-0.1927850395441...|\n",
            "|[-0.05503883957862854,0.3008425533771515,-0.017401527613401413,-0.22713385522...|\n",
            "|[0.21699899435043335,-0.4026758670806885,0.1304507702589035,0.260321527719497...|\n",
            "+--------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sparknlp.annotator import RoBertaForQuestionAnswering"
      ],
      "metadata": {
        "id": "g86pMwlQ2MJT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "should use `roberta_base_qa_squad2` by deafult, is using `roberta_base_qa_squad2` ✅"
      ],
      "metadata": {
        "id": "2VWyUPws2t0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = MultiDocumentAssembler() \\\n",
        "    .setInputCols([\"question\", \"context\"]) \\\n",
        "    .setOutputCols([\"document_question\", \"document_context\"])\n",
        "\n",
        "spanClassifier = RoBertaForQuestionAnswering.pretrained() \\\n",
        "    .setInputCols([\"document_question\", \"document_context\"]) \\\n",
        "    .setOutputCol(\"answer\")\\\n",
        "    .setCaseSensitive(True)\n",
        "\n",
        "pipeline = Pipeline(stages=[\n",
        "    documentAssembler,\n",
        "    spanClassifier\n",
        "])\n",
        "\n",
        "data = spark.createDataFrame([\n",
        "    [\"What is my name?\", \"My name is Clara and I live in Berkeley.\"]\n",
        "]).toDF(\"question\", \"context\")\n",
        "\n",
        "model = pipeline.fit(data)\n",
        "result = model.transform(data)\n",
        "\n",
        "result.select(\"answer.result\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7QjJ-eV1vnj",
        "outputId": "db93a2f1-44f9-4f67-d03a-1fa2a82a3294"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "roberta_base_qa_squad2 download started this may take some time.\n",
            "Approximate size to download 441.7 MB\n",
            "[OK!]\n",
            "+-------+\n",
            "|result |\n",
            "+-------+\n",
            "|[Clara]|\n",
            "+-------+\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:tempspark]",
      "language": "python",
      "name": "conda-env-tempspark-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}